{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. BUSINESS UNDERSTANDING\n",
    "The purpose of this use case is analyzing tweet sentiment class. The dataset has more than 1 million rows so it needs to be develop use Spark. But, in this section I will develop use Jupyter Notebook only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DATA UNDERSTANDING\n",
    "In this section, we need to load library and install the package needed to do sentiment analysis. Then, we will load the dataset and see the characteristic of the dataset. The dataset for this cases has already saved in csv format named clean_tweet.csv. The data has already clean enough, but it still need to be exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Install the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\programdata\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from textblob)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting re\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement re (from versions: )\n",
      "No matching distribution found for re\n",
      "You are using pip version 9.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\programdata\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# package that will use on pre-processing data\n",
    "!pip install nltk\n",
    "!pip install textblob\n",
    "!pip install re\n",
    "!pip install wordcloud\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\haniam064181\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "#import nltk for natural language toolkit\n",
    "import nltk\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "#import string, regex, , uniqcode\n",
    "import re, string, unicodedata\n",
    "\n",
    "#import sklearn preprocessing \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#import sklearn for modeling\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import sklearn for model evaluation \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#import visualization module \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "#import tqdm \n",
    "from tqdm import tqdm \n",
    "tqdm.pandas()\n",
    "\n",
    "#import beaurtiful soup \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#save model \n",
    "import pickle \n",
    "\n",
    "#textblob\n",
    "from textblob import Word\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that s a bummer you shoulda got david car...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can t update his facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dived many times for the ball managed to sav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it s not behaving at all i m mad why am i h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  awww that s a bummer you shoulda got david car...       0\n",
       "1  is upset that he can t update his facebook by ...       0\n",
       "2  i dived many times for the ball managed to sav...       0\n",
       "3     my whole body feels itchy and like its on fire       0\n",
       "4  no it s not behaving at all i m mad why am i h...       0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import dataset \n",
    "data=pd.read_csv('clean_tweet.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 2 columns):\n",
      "text      1596753 non-null object\n",
      "target    1600000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 24.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# get info of dataset\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset has 2 columns and 1600000 rows.<br>\n",
    "``text`` column represents tweet.<br>\n",
    "``target`` column represents sentiment class : 0 for negative and 1 for positive. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DATA PREPROCESSING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will prepare the dataset (to be used on the modelling) such as drop duplicate and data preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Drop duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(keep = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text      1509626\n",
       "target    1509626\n",
       "dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After drop duplicates, dataset left 1509626 rows. It means that there are 90374 duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Stopwords removal\n",
    "Remove stop words that won't give any insight, or save the words that will give impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stop = stopwords.words('english')\n",
    "data['text'] = data['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "data['text'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Rare words removal\n",
    "Remove the words that infrequently shown in data. I choose to show 1000 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anttt                     1\n",
       "hourto                    1\n",
       "prufung                   1\n",
       "travelor                  1\n",
       "rofltrax                  1\n",
       "haidee                    1\n",
       "adammmmmm                 1\n",
       "amaizinggggggggggggggg    1\n",
       "baalika                   1\n",
       "fucccckkkkkkkkkk          1\n",
       "musiem                    1\n",
       "ismaya                    1\n",
       "nickinix                  1\n",
       "gooooosh                  1\n",
       "smallgroup                1\n",
       "rinnah                    1\n",
       "hwen                      1\n",
       "slenger                   1\n",
       "resterant                 1\n",
       "zyder                     1\n",
       "midtwenties               1\n",
       "dreambank                 1\n",
       "thundi                    1\n",
       "whrn                      1\n",
       "parrie                    1\n",
       "consigliere               1\n",
       "notyours                  1\n",
       "kinnear                   1\n",
       "robcrotch                 1\n",
       "keeviiiinnn               1\n",
       "                         ..\n",
       "sundayrollcall            1\n",
       "clossaaaaaa               1\n",
       "pallachinkin              1\n",
       "duchonvy                  1\n",
       "talie                     1\n",
       "semperamy                 1\n",
       "ctabor                    1\n",
       "keydown                   1\n",
       "fhdskghakgahak            1\n",
       "kanisa                    1\n",
       "buoyant                   1\n",
       "quebecois                 1\n",
       "cassady                   1\n",
       "auuurite                  1\n",
       "failling                  1\n",
       "amedd                     1\n",
       "helpfulbut                1\n",
       "esay                      1\n",
       "thehott                   1\n",
       "thomyorkwasright          1\n",
       "punkarse                  1\n",
       "rockinthatting            1\n",
       "pshiih                    1\n",
       "andjob                    1\n",
       "brazzaz                   1\n",
       "summerrrrrrrrrr           1\n",
       "adslam                    1\n",
       "pallakad                  1\n",
       "hecktic                   1\n",
       "soonxx                    1\n",
       "Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the rare words\n",
    "rare_word = pd.Series(' '.join(data['text']).split()).value_counts()[-1000:]\n",
    "rare_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         awww bummer shoulda got david carr third day\n",
       "1    upset update facebook texting might cry result...\n",
       "2    dived many times ball managed save rest go bounds\n",
       "3                     whole body feels itchy like fire\n",
       "4                                     behaving mad see\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing rare words\n",
    "rare_word = list(rare_word.index)\n",
    "data['text'] = data['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in rare_word))\n",
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Spelling correction\n",
    "Correct spelling in english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           www summer should got david care third day\n",
       "1    upset update facebook testing might cry result...\n",
       "2    dived many times ball managed save rest go bounds\n",
       "3                     whole body feels itchy like fire\n",
       "4                                     behaving mad see\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][:5].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Lemmatization\n",
    "Reduces the word-forms to linguistically valid lemmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data['text'] = data['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. DATA EXPLORATION\n",
    "In this section, I will EDA the dataset to get any insight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Count sentiment class\n",
    "We want to find which text are often discussed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count sentiment \n",
    "sentiment = data.groupby(['target'])['target'].count()\n",
    "sentiment\n",
    "\n",
    "#make dataframe that will be created a chart \n",
    "chart = pd.DataFrame(sentiment)\n",
    "chart['tweet_count'] = chart['target']\n",
    "chart.drop(['target'], axis = 1, inplace = True )\n",
    "chart = chart.reset_index()\n",
    "\n",
    "#make a proportion of the number of tweet of each sentiment \n",
    "chart['percent'] = chart['tweet_count']/chart['tweet_count'].sum()\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data above, we can know that data has :\n",
    "- **Negative** sentiment (target==0) : **50,3%**\n",
    "- **Positive** sentiment (target==1) : **49,7%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Visualization of sentiment class\n",
    "Visualize the sentiment class to see which class has the highest tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Barchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bar plot visualization \n",
    "ax = sns.barplot(x= 'target', y='tweet_count', data=chart)\n",
    "ax.set_title('Barplot Sentiment Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie chart visualization\n",
    "colors = ['red','lightskyblue']\n",
    "explode = (0.2, 0)  # explode 1st slice\n",
    "figure = plt.figure(figsize= (10,6))\n",
    "plt.pie(chart['tweet_count'], explode=explode, labels=chart['target'], colors=colors,\n",
    "autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.title('Pie Chart Sentiment Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above bar chart and pie chart, we can see that :\n",
    "- **Negative** sentiment (the red one) is the highest sentiment from user (50,3%).\n",
    "- Negative and positive sentiment class is a little bit different, it has only 0,6% differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define negative and positive sentiment \n",
    "negative = data.loc[data['target'] == 0]\n",
    "positive  = data.loc[data['target'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all the sentiment text comments into one paragraph\n",
    "all_description_positive = \"\".join(positive.text.values)\n",
    "all_description_negative = \"\".join(negative.text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a wordcloud \n",
    "def create_word_cloud(string):\n",
    "    cloud = WordCloud(background_color = \"white\", max_words = 200, stopwords = set(STOPWORDS)).generate(string)\n",
    "    plt.imshow(cloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positve sentiment class\n",
    "create_word_cloud(all_description_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the word cloud above, we can know that the words for positive sentiment class are love, good, thank, and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#negative sentiment class\n",
    "create_word_cloud(all_description_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the word cloud above, we can know that the words for negative sentiment class are room, hotel, front, desk. From those word indicate that the user complains about Hotel's services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. MODELING\n",
    "In this section, I will do :\n",
    "1. Feature extraction use :\n",
    "   - Count vectorizer\n",
    "   - TF-IDF vectorize\n",
    "2. Modeling development use :\n",
    "   - Logistic Regression\n",
    "   - Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizer \n",
    "The output of Count Vectorizer is binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF vectorizer \n",
    "TF (term frequency) – IDF (inverse document frequency). The output of TF-IDF is decimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizer N-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer_ngram = CountVectorizer(ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Train Test Split\n",
    "Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countvectorizer\n",
    "X_vectorizer = count_vectorizer.fit_transform(X)\n",
    "\n",
    "#tfidf vectorizer\n",
    "X_tfidf = tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngram vectorizer\n",
    "X_ngram = count_vectorizer_ngram.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split using countvectorizer \n",
    "train_X_vectorizer, test_X_vectorizer, train_y, test_y = train_test_split(X_vectorizer, y, test_size=0.3, random_state=0)\n",
    "\n",
    "#train test split using tfidfvectorizer \n",
    "train_X_tfidf, test_X_tfidf, train_y, test_y = train_test_split(X_tfidf, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split using tfidfvectorizer \n",
    "train_X_ngram, test_X_ngram, train_y, test_y = train_test_split(X_ngram, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Model Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use 2 algorithms :\n",
    "1. Logistic Regression\n",
    "2. Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countvectorizer \n",
    "Lr_vect = LogisticRegression()\n",
    "Lr_vect.fit(train_X_vectorizer,train_y)\n",
    "Lr_pred_vect_train = Lr_vect.predict(train_X_vectorizer)\n",
    "Lr_pred_vect_test = Lr_vect.predict(test_X_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDFVectorizer\n",
    "Lr_tfidf = LogisticRegression()\n",
    "Lr_tfidf.fit(train_X_tfidf,train_y)\n",
    "Lr_pred_tfidf_train = Lr_tfidf.predict(train_X_tfidf)\n",
    "Lr_pred_tfidf_test = Lr_tfidf.predict(test_X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NgramVectorizer\n",
    "Lr_ngram = LogisticRegression()\n",
    "Lr_ngram.fit(train_X_ngram,train_y)\n",
    "Lr_pred_ngram_train = Lr_ngram.predict(train_X_ngram)\n",
    "Lr_pred_ngram_test = Lr_ngram.predict(test_X_ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countvectorizer\n",
    "NB_vect = MultinomialNB()\n",
    "NB_vect.fit(train_X_vectorizer,train_y)\n",
    "NB_pred_vect_train = NB_vect.predict(train_X_vectorizer)\n",
    "NB_pred_vect_test = NB_vect.predict(test_X_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDFVectorizer\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "NB_tfidf = MultinomialNB()\n",
    "NB_tfidf.fit(train_X_tfidf,train_y)\n",
    "NB_pred_tfidf_train = NB_tfidf.predict(train_X_tfidf)\n",
    "NB_pred_tfidf_test = NB_tfidf.predict(test_X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NgramVectorizer\n",
    "NB_ngram = MultinomialNB()\n",
    "NB_ngram.fit(train_X_ngram,train_y)\n",
    "NB_pred_ngram_train = NB_ngram.predict(train_X_ngram)\n",
    "NB_pred_ngram_test = NB_ngram.predict(test_X_ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following options are kind of model evaluation that used :\n",
    "- Accuracy = (TP + TN) / (P + N)\n",
    "- Precision = TP / (TP + FP)\n",
    "- Recall = TP / (TP + FN)\n",
    "- F-measure = 2TP / (2TP + FP + FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using count vectorizer\n",
    "print(\"______________ Countvectorizer ______________\")\n",
    "Lr_recall_vec_train = recall_score(train_y, Lr_pred_vect_train, average=\"micro\")\n",
    "Lr_recall_vec_test = recall_score(test_y, Lr_pred_vect_test,average=\"micro\") \n",
    "\n",
    "Lr_precision_vec_train = precision_score(train_y, Lr_pred_vect_train,average=\"micro\")\n",
    "Lr_precision_vec_test = precision_score(test_y, Lr_pred_vect_test,average=\"micro\")\n",
    "\n",
    "Lr_f1_score_vec_train = f1_score(train_y, Lr_pred_vect_train,average=\"micro\")\n",
    "Lr_f1_score_vec_test = f1_score(test_y,Lr_pred_vect_test,average=\"micro\")\n",
    "\n",
    "print('Information :')\n",
    "print('Recall train & test     : %.2f%%' % (Lr_recall_vec_train * 100), '&', '%.2f%%' % (Lr_recall_vec_test * 100))\n",
    "print('Precision train & test  : %.2f%%' % (Lr_precision_vec_train * 100), '&', '%.2f%%' % (Lr_precision_vec_test * 100))\n",
    "print('F1 Score train & test   : %.2f%%' % (Lr_f1_score_vec_train * 100), '&', '%.2f%%' % (Lr_f1_score_vec_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using count vectorizer\n",
    "print(\"______________ TF-IDF ______________\")\n",
    "\n",
    "Lr_recall_tfidf_train = recall_score(train_y, Lr_pred_tfidf_train, average=\"micro\")\n",
    "Lr_recall_tfidf_test = recall_score(test_y, Lr_pred_tfidf_test,average=\"micro\") \n",
    "\n",
    "Lr_precision_tfidf_train = precision_score(train_y, Lr_pred_tfidf_train,average=\"micro\")\n",
    "Lr_precision_tfidf_test = precision_score(test_y, Lr_pred_tfidf_test,average=\"micro\")\n",
    "\n",
    "Lr_f1_score_tfidf_train = f1_score(train_y, Lr_pred_tfidf_train,average=\"micro\")\n",
    "Lr_f1_score_tfidf_test = f1_score(test_y,Lr_pred_tfidf_test,average=\"micro\")\n",
    "\n",
    "print('Information :')\n",
    "print('Recall train & test     : %.2f%%' % (Lr_recall_tfidf_train * 100), '&', '%.2f%%' % (Lr_recall_tfidf_test * 100))\n",
    "print('Precision train & test  : %.2f%%' % (Lr_precision_tfidf_train * 100), '&', '%.2f%%' % (Lr_precision_tfidf_test * 100))\n",
    "print('F1 Score train & test   : %.2f%%' % (Lr_f1_score_tfidf_train * 100), '&', '%.2f%%' % (Lr_f1_score_vec_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using count vectorizer\n",
    "print(\"______________ Countvectorizer N-gram ______________\")\n",
    "\n",
    "Lr_recall_ngram_train = recall_score(train_y, Lr_pred_ngram_train, average=\"micro\")\n",
    "Lr_recall_ngram_test = recall_score(test_y, Lr_pred_ngram_test,average=\"micro\") \n",
    "\n",
    "Lr_precision_ngram_train = precision_score(train_y, Lr_pred_ngram_train,average=\"micro\")\n",
    "Lr_precision_ngram_test = precision_score(test_y, Lr_pred_ngram_test,average=\"micro\")\n",
    "\n",
    "Lr_f1_score_ngram_train = f1_score(train_y, Lr_pred_ngram_train,average=\"micro\")\n",
    "Lr_f1_score_ngram_test = f1_score(test_y,Lr_pred_ngram_test,average=\"micro\")\n",
    "\n",
    "print('Information :')\n",
    "print('Recall train & test     : %.2f%%' % (Lr_recall_ngram_train * 100), '&', '%.2f%%' % (Lr_recall_ngram_test * 100))\n",
    "print('Precision train & test  : %.2f%%' % (Lr_precision_ngram_train * 100), '&', '%.2f%%' % (Lr_precision_ngram_test * 100))\n",
    "print('F1 Score train & test   : %.2f%%' % (Lr_f1_score_ngram_train * 100), '&', '%.2f%%' % (Lr_f1_score_ngram_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find model evaluation for naive bayes\n",
    "# using count vectorizer\n",
    "print(\"______________ Countvectorizer ______________\")\n",
    "\n",
    "NB_recall_vec_train = recall_score(train_y, NB_pred_vect_train, average=\"micro\")\n",
    "NB_recall_vec_test = recall_score(test_y, NB_pred_vect_test,average=\"micro\") \n",
    "\n",
    "NB_precision_vec_train = precision_score(train_y, NB_pred_vect_train,average=\"micro\")\n",
    "NB_precision_vec_test = precision_score(test_y, NB_pred_vect_test,average=\"micro\")\n",
    "\n",
    "NB_f1_score_vec_train = f1_score(train_y, NB_pred_vect_train,average=\"micro\")\n",
    "NB_f1_score_vec_test = f1_score(test_y,NB_pred_vect_test,average=\"micro\")\n",
    "\n",
    "print('Information :')\n",
    "print('Recall train & test     : %.2f%%' % (NB_recall_vec_train * 100), '&', '%.2f%%' % (NB_recall_vec_test * 100))\n",
    "print('Precision train & test  : %.2f%%' % (NB_precision_vec_train * 100), '&', '%.2f%%' % (NB_precision_vec_test * 100))\n",
    "print('F1 Score train & test   : %.2f%%' % (NB_f1_score_vec_train * 100), '&', '%.2f%%' % (NB_f1_score_vec_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using count vectorizer\n",
    "print(\"______________ TF-IDF ______________\")\n",
    "\n",
    "NB_recall_tfidf_train = recall_score(train_y, NB_pred_tfidf_train, average=\"micro\")\n",
    "NB_recall_tfidf_test = recall_score(test_y, NB_pred_tfidf_test,average=\"micro\") \n",
    "\n",
    "NB_precision_tfidf_train = precision_score(train_y, NB_pred_tfidf_train,average=\"micro\")\n",
    "NB_precision_tfidf_test = precision_score(test_y, NB_pred_tfidf_test,average=\"micro\")\n",
    "\n",
    "NB_f1_score_tfidf_train = f1_score(train_y, NB_pred_tfidf_train,average=\"micro\")\n",
    "NB_f1_score_tfidf_test = f1_score(test_y,NB_pred_tfidf_test,average=\"micro\")\n",
    "\n",
    "print('Information :')\n",
    "print('Recall train & test     : %.2f%%' % (NB_recall_tfidf_train * 100), '&', '%.2f%%' % (NB_recall_tfidf_test * 100))\n",
    "print('Precision train & test  : %.2f%%' % (NB_precision_tfidf_train * 100), '&', '%.2f%%' % (NB_precision_tfidf_test * 100))\n",
    "print('F1 Score train & test   : %.2f%%' % (NB_f1_score_tfidf_train * 100), '&', '%.2f%%' % (NB_f1_score_vec_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result of social media analysis above, we can know that :\n",
    "1. Dataset has **negative sentiment class 50,3%** and **positive sentiment class 49,7%**.\n",
    "2. The most frequent words for **negative** sentiment class are **room, hotel, front, desk**. It indicates that user complains about Hotel's service.\n",
    "3. The most frequent words for **positive** sentiment class are **love, good, thank, and time**.\n",
    "4. Model Machine Learning\n",
    "    1. **Logistic Regression** :\n",
    "        - Countvectorizer : all values of recall, precision, and F-score for train and test are 79.93% & 76.49%.\n",
    "        - TF-IDF : all values of recall and precision for train and test are 79.05% & 76.70%, while F-score for train and test are 79.05% & 76.49%.\n",
    "        - We can conclude that for this dataset and algorithm, **TF-IDF is better** than Countvectorizer because of the difference between train and test are 2,35% (less than Countvectorizer has).\n",
    "    \n",
    "    2. **Naive Bayes** :\n",
    "       - Countvectorizer : all values of recall, precision, and F-score for train and test are 78.71% & 75.63%.\n",
    "       - TF-IDF : all values of recall and precision for train and test are 78.72% & 74.94%, while F-score for train and test are 78.72% & 75.63%.\n",
    "       - We can conclude that for this dataset and algorithm, **Countvectorizer is better** than TF-IDF because of the difference between train and test are 3,08% (less than TF-IDF has)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
